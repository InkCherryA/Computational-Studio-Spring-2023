<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Edit page title -->
    <title>MAPPING</title>
    <link rel="stylesheet" href="../style.css">
    <!-- Edit style sheet link -->
    <link rel="stylesheet" href="./0001.css">
</head>
<body>
    <div id="header">
        <!-- Edit site title -->
        <a href="../index.html" id="logo">Simulated | Spring 2020</a>
    </div>
    <div class="pages">
        <div id="page-info" class="page">
            <!-- Edit project cover -->
            <a href="./src/000img.png"><img src="./src/000img.png" alt="" class="thumbnail"></a>
            <div id="info">
                <!-- Edit project title -->
                <div class="text1">MAPPING | 2020</div>
                <!-- Edit project description -->

                <div class="text3" class="flexchild">
                    Midjourney is a text to image (txt2img) machine learning (ML) model. It takes in a textual prompt from the user, generates a grid of four images in response to the prompt. The user then has the option to reroll, upscale or create variations. Midjourney and a few other txt2img models are based on a type of artifitial neural network called the autoencoder. The autoencoder compresses (encoding) many features into far fewer variables, which could later be decompressed (decoding). In a txt2img model's case, a language model and an image model are trained separately. After the textual input from the user is encoded by the language model, the encoded data will be translated and used for decoding on the image model.
                    <br><br>
                    The study experiments with this technology. With different textual prompts, game maps of different types are generated by Midjourney. Through a series of back and forth between the human discriminator and the machine generator, images are filtered and selected. This human machine relationship almost becomes adversarial, similar to another ML model, the GAN (generative adversarial network).
                    <br><br>
                    After an image is selected, human imagination is required to interpret many of the objects, since the machine generated image is often ambiguous on the content that are not specified in the prompt. Later, the interpreted content can be fed back into the textual prompt and specify the generation further.
                </div>
            </div>
            <a href="https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png#/media/File:Autoencoder_schema.png"><img src="https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png" title="Autoencoder Schema" class="thumbnail"></a>
           
        </div>

        <div id="page-content" class="page">
            <!-- Edit project content -->
            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The below images are generated by Midjourney with the prompt: 
                    <br>
                    <span class="bold">"A video game map"</span>.
                </div>
                

            </div>

            <div class="flexdiv">
                <a href="./src/002img.png"><img src="./src/002img.png" alt="" class="flexchild"></a>
                <a href="./src/006img.png"><img src="./src/006img.png" alt="" class="flexchild"></a>
                <a href="./src/003img.png"><img src="./src/003img.png" alt="" class="flexchild"></a>
            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The first two images are generated by Midjourney with the prompt: 
                    <br>
                    <span class="bold">"A video game map of galactic world"</span>.
                    <br>
                    The second two images are variations of the second and third image.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/001img.png"><img src="./src/001img.png" alt="" class="flexchild"></a>
                <a href="./src/019img.png"><img src="./src/019img.png" alt="" class="flexchild"></a>
                <a href="./src/017img.png"><img src="./src/017img.png" alt="" class="flexchild"></a>
                <a href="./src/020img.png"><img src="./src/020img.png" alt="" class="flexchild"></a>
            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The below images are generated by Midjourney with the prompt:
                    <br>
                    <span class="bold">"A video game map of an escape room which is a sci-fi robot workshop"</span>.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/018img.png"><img src="./src/018img.png" alt="" class="flexchild"></a>
                <a href="./src/012img.png"><img src="./src/012img.png" alt="" class="flexchild"></a>
                <a href="./src/005img.png"><img src="./src/005img.png" alt="" class="flexchild"></a>

            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The below images are generated by Midjourney with the prompt:
                    <br> 
                    <span class="bold">"Floor plan of a video game escape room, sci-fi, robot workshop"</span>.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/007img.png"><img src="./src/007img.png" alt="" class="flexchild"></a>
                <a href="./src/008img.png"><img src="./src/008img.png" alt="" class="flexchild"></a>
                <a href="./src/010img.png"><img src="./src/010img.png" alt="" class="flexchild"></a>

            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The third image is blended by Midjourney from the first two images.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/011img.png"><img src="./src/011img.png" alt="" class="flexchild"></a>
                <a href="./src/016img.png"><img src="./src/016img.png" alt="" class="flexchild"></a>
                <a href="./src/009img.png"><img src="./src/009img.png" alt="" class="flexchild"></a>

            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    The first image is generated by Midjourney with the prompt: 
                    <br>
                    <span class="bold">"A sci-fi game map within a house, escape room feeling"</span>.
                    <br>
                    The second image is an upscaled version of the third image from the grid.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/004img.png"><img src="./src/004img.png" alt="" class="flexchild"></a>
                <a href="./src/013img.png"><img src="./src/013img.png" alt="" class="flexchild"></a>

            </div>

            <div class="flexdiv">
                <div class="text3" class="flexchild">
                    Using the upscaled image, ambiguous objects are interpreted and labeled by a human.
                    <br>
                    It is a combination of and comparison between machine and human imagination.
                </div>
            </div>

            <div class="flexdiv">
                <a href="./src/014img.png"><img src="./src/014img.png" alt="" class="flexchild"></a>
            </div>

        </div>
        </div>
    </div>
   </body>
</html>